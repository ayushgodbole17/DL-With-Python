{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTcfwjl7D6X6"
   },
   "outputs": [],
   "source": [
    "# SEQUENCE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-HCpFAgEJJV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6ogkLa2EuFq",
    "outputId": "0a622eba-2bbb-4a58-dd08-ec7678d8b803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  9223k      0  0:00:08  0:00:08 --:--:-- 16.8M\n",
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz\n",
    "\n",
    "!rm -r aclImdb/train/unsup\n",
    "\n",
    "import os, pathlib, shutil, random\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir/\"val\"\n",
    "train_dir = base_dir/\"train\"\n",
    "\n",
    "for category in (\"neg\", \"pos\"):\n",
    "  os.makedirs(val_dir/category)\n",
    "  files = os.listdir(train_dir/category)\n",
    "  random.Random(1337).shuffle(files)\n",
    "  num_val_samples = int(0.2 * len(files))\n",
    "  val_files = files[-num_val_samples:]\n",
    "  for fname in val_files:\n",
    "    shutil.move(train_dir/category/fname, val_dir/category/fname)\n",
    "\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size)\n",
    "val_ds = keras.utils.text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n",
    "test_ds = keras.utils.text_dataset_from_directory('aclImdb/test', batch_size=batch_size)\n",
    "\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loV--udJEReX"
   },
   "outputs": [],
   "source": [
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = layers.TextVectorization(max_tokens=max_tokens, output_mode='int', output_sequence_length=max_length)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zst6bVd9FUP5",
    "outputId": "19be01b2-94eb-46ed-c9e1-f95f7ece66bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " tf.one_hot (TFOpLambda)     (None, None, 600)         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               162048    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,113\n",
      "Trainable params: 162,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Bidirectional RNN\n",
    "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "embedded = tf.one_hot(inputs, depth=max_length)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ny7kv6ThGF_-",
    "outputId": "b88f347c-7d81-47aa-8729-743d3e91ef86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 42s 53ms/step - loss: 0.5839 - accuracy: 0.6985 - val_loss: 0.5097 - val_accuracy: 0.7908\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.4890 - accuracy: 0.7970 - val_loss: 0.4222 - val_accuracy: 0.8210\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.4470 - accuracy: 0.8122 - val_loss: 0.4264 - val_accuracy: 0.8342\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.4247 - accuracy: 0.8234 - val_loss: 0.3960 - val_accuracy: 0.8308\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.4071 - accuracy: 0.8293 - val_loss: 0.3947 - val_accuracy: 0.8304\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.4000 - accuracy: 0.8359 - val_loss: 0.4234 - val_accuracy: 0.8210\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.3891 - accuracy: 0.8418 - val_loss: 0.3845 - val_accuracy: 0.8390\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.3855 - accuracy: 0.8435 - val_loss: 0.4161 - val_accuracy: 0.8220\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.3862 - accuracy: 0.8452 - val_loss: 0.3859 - val_accuracy: 0.8374\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.3820 - accuracy: 0.8449 - val_loss: 0.4206 - val_accuracy: 0.8260\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 0.3899 - accuracy: 0.8349\n",
      "Test acc: 0.835\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\", save_best_only=True)]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\") \n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOtjvh__HpQC"
   },
   "source": [
    "2 ways to use word embeddings: Adding it as a layer and learning embeddings with models, or using pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoLoaGLmGMD8",
    "outputId": "557ec5cb-eb72-4be1-9709-8d2d2855d9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               73984     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,194,049\n",
      "Trainable params: 5,194,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#adding as a layer\n",
    "\n",
    "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "embeddings = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embeddings)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Na-sN-HIM30",
    "outputId": "bb7e8e29-4ca9-4404-f176-97d4098a77f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 35s 51ms/step - loss: 0.4601 - accuracy: 0.7946 - val_loss: 0.3372 - val_accuracy: 0.8692\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.3046 - accuracy: 0.8903 - val_loss: 0.3261 - val_accuracy: 0.8798\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.2415 - accuracy: 0.9157 - val_loss: 0.4764 - val_accuracy: 0.8302\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.2002 - accuracy: 0.9313 - val_loss: 0.3069 - val_accuracy: 0.8810\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.1697 - accuracy: 0.9441 - val_loss: 0.3299 - val_accuracy: 0.8856\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.1434 - accuracy: 0.9527 - val_loss: 0.3837 - val_accuracy: 0.8672\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.1162 - accuracy: 0.9633 - val_loss: 0.3751 - val_accuracy: 0.8848\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.0929 - accuracy: 0.9704 - val_loss: 0.4141 - val_accuracy: 0.8796\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.0809 - accuracy: 0.9754 - val_loss: 0.4767 - val_accuracy: 0.8754\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0666 - accuracy: 0.9801 - val_loss: 0.4750 - val_accuracy: 0.8768\n",
      "782/782 [==============================] - 20s 24ms/step - loss: 0.3622 - accuracy: 0.8599\n",
      "Test acc: 0.860\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(\"embeddings_bidir_lstm.keras\", save_best_only=True)]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"embeddings_bidir_lstm.keras\") \n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tK-XulPxIYsb",
    "outputId": "754701e9-2c8b-41f1-906e-fab9461e0e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64)               73984     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,194,049\n",
      "Trainable params: 5,194,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#using masking\n",
    "\n",
    "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "embeddings = layers.Embedding(input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embeddings)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bADzDdRI9NU",
    "outputId": "ba23cf9c-305e-4c3a-e553-6d642ea787aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 50s 68ms/step - loss: 0.3995 - accuracy: 0.8201 - val_loss: 0.3504 - val_accuracy: 0.8510\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.2297 - accuracy: 0.9119 - val_loss: 0.2942 - val_accuracy: 0.8798\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.1648 - accuracy: 0.9387 - val_loss: 0.3182 - val_accuracy: 0.8872\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 0.1264 - accuracy: 0.9552 - val_loss: 0.3334 - val_accuracy: 0.8784\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.0890 - accuracy: 0.9690 - val_loss: 0.3843 - val_accuracy: 0.8796\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.0694 - accuracy: 0.9758 - val_loss: 0.4016 - val_accuracy: 0.8820\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 0.0476 - accuracy: 0.9833 - val_loss: 0.4702 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.4594 - val_accuracy: 0.8780\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.5681 - val_accuracy: 0.8832\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.5681 - val_accuracy: 0.8712\n",
      "782/782 [==============================] - 25s 30ms/step - loss: 0.3363 - accuracy: 0.8660\n",
      "Test acc: 0.866\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(\"embeddings_bidir_lstm_mask.keras\", save_best_only=True)]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"embeddings_bidir_lstm_mask.keras\") \n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwFZ4uEfJAjD",
    "outputId": "33d927dc-6189-4d4e-f2cf-34c49fc0b3d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-19 17:02:54--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2022-07-19 17:02:55--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2022-07-19 17:02:55--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 41s  \n",
      "\n",
      "2022-07-19 17:05:37 (5.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Pretrained \n",
    "#2 popular options: Word2Vec and GloVe\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vAXpoMHTJyO0",
    "outputId": "215fe9bc-8fcd-4022-ae06-d0c866c14650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Parsing the glove embedding file\n",
    "\n",
    "import numpy as np\n",
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "embeddings_index = {} \n",
    "with open(path_to_glove_file) as f:\n",
    " for line in f:\n",
    "   word, coefs = line.split(maxsplit=1)\n",
    "   coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "   embeddings_index[word] = coefs\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbmY2UxGJ_4L"
   },
   "outputs": [],
   "source": [
    "#Create GloVe embedding matrix\n",
    "\n",
    "embedding_dim = 100\n",
    "vocabulary = text_vectorization.get_vocabulary() \n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary)))) \n",
    "embedding_matrix = np.zeros((max_tokens, embedding_dim)) \n",
    "for word, i in word_index.items():\n",
    " if i < max_tokens:\n",
    "   embedding_vector = embeddings_index.get(word)\n",
    " if embedding_vector is not None: \n",
    "   embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXysiV8oKS9r"
   },
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(max_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                                   trainable=False,\n",
    "                                   mask_zero=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmgvifw1Kl8O",
    "outputId": "4b80ab69-1a8c-4d36-c039-c469ff4989a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 64)               34048     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,034,113\n",
      "Trainable params: 34,113\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 45s 60ms/step - loss: 0.5842 - accuracy: 0.6849 - val_loss: 0.6639 - val_accuracy: 0.7134\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.4606 - accuracy: 0.7901 - val_loss: 0.4207 - val_accuracy: 0.7996\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.4063 - accuracy: 0.8194 - val_loss: 0.3751 - val_accuracy: 0.8314\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.3719 - accuracy: 0.8406 - val_loss: 0.3562 - val_accuracy: 0.8444\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.3487 - accuracy: 0.8514 - val_loss: 0.3600 - val_accuracy: 0.8388\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.3250 - accuracy: 0.8622 - val_loss: 0.3281 - val_accuracy: 0.8552\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.3058 - accuracy: 0.8748 - val_loss: 0.3328 - val_accuracy: 0.8540\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 35s 55ms/step - loss: 0.2893 - accuracy: 0.8814 - val_loss: 0.3074 - val_accuracy: 0.8722\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.2764 - accuracy: 0.8861 - val_loss: 0.3348 - val_accuracy: 0.8550\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.2604 - accuracy: 0.8957 - val_loss: 0.3101 - val_accuracy: 0.8706\n",
      "782/782 [==============================] - 22s 25ms/step - loss: 0.3086 - accuracy: 0.8692\n",
      "Test acc: 0.869\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = embedding_layer(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\", save_best_only=True)]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFQK7z7xKuac"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dltext2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
