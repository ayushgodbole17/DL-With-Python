{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552c2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d62575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff1c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, trlab), (test, telab) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09378fa7",
   "metadata": {},
   "source": [
    "# SEQUENTIAL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53175c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Approach 1:\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\"\"\"\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "779d9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.weights (Haven't been created yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca94f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f110da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b059215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.09671529,  0.09901774,  0.02665168,  0.1604566 ,  0.15425214,\n",
       "          0.17075008,  0.2825625 , -0.27594325,  0.29096723,  0.05557388,\n",
       "          0.29784083,  0.04950771, -0.27936178,  0.20785278, -0.24713138,\n",
       "          0.27431554,  0.04867598, -0.01867783,  0.12842888, -0.05664144,\n",
       "          0.24610299,  0.0524472 , -0.19779262, -0.00081921, -0.13091876,\n",
       "          0.15476006,  0.02480799,  0.2872755 , -0.27338374, -0.20966783,\n",
       "          0.02600387, -0.10991028,  0.16346559,  0.25868595,  0.134464  ,\n",
       "         -0.10142887, -0.23895395,  0.2267468 ,  0.2064991 , -0.00909308,\n",
       "          0.14954805, -0.1652582 , -0.03713682, -0.2805137 ,  0.01168534,\n",
       "          0.06794873, -0.10697612, -0.06194219, -0.26079255,  0.00477907,\n",
       "          0.15892783, -0.04773122, -0.2844241 , -0.22449283, -0.02844977,\n",
       "         -0.23900717, -0.21861795, -0.28319222,  0.10552576,  0.06034222,\n",
       "          0.27956355,  0.15095082,  0.2922094 ,  0.00756326],\n",
       "        [ 0.17485386, -0.28049293,  0.14034995,  0.19863045, -0.03770098,\n",
       "         -0.11869365,  0.18785185,  0.01170513,  0.21135223,  0.18176985,\n",
       "         -0.08783267,  0.02417129, -0.00370848, -0.2299995 , -0.01447868,\n",
       "         -0.0198268 , -0.28305003, -0.11962667, -0.23796308, -0.29798576,\n",
       "         -0.09093894, -0.21975678, -0.06289533, -0.17624184, -0.01923186,\n",
       "         -0.04624406, -0.23366511, -0.07379229, -0.156453  ,  0.147661  ,\n",
       "         -0.03332394,  0.00425902, -0.2767756 ,  0.18416697, -0.25796205,\n",
       "         -0.20881416, -0.07757677, -0.26209998, -0.28482178,  0.0971466 ,\n",
       "          0.04587796,  0.0250062 , -0.28743523,  0.21721768,  0.00528398,\n",
       "          0.29247314,  0.03373358,  0.09091339, -0.00810841,  0.12851956,\n",
       "          0.14509961, -0.08497101,  0.06628439,  0.19211286,  0.10264099,\n",
       "         -0.17680478,  0.10568395, -0.2407218 , -0.04201835,  0.18271384,\n",
       "         -0.01110137,  0.09538573, -0.22368725, -0.06136607],\n",
       "        [ 0.24359435,  0.14368922,  0.05028808, -0.01005927, -0.04756689,\n",
       "          0.06569427,  0.17679936,  0.01837367,  0.14872992,  0.19492376,\n",
       "         -0.0942792 , -0.14062579,  0.16955575, -0.13571851, -0.08699092,\n",
       "         -0.20176268,  0.25529987,  0.11875015,  0.0952239 , -0.25254807,\n",
       "          0.2064147 ,  0.00948843, -0.15041037,  0.25177276, -0.09754907,\n",
       "         -0.16240987,  0.15948561, -0.18386582,  0.24386382, -0.14989203,\n",
       "          0.18192074,  0.11157474,  0.01046282,  0.09641686, -0.03596908,\n",
       "         -0.18515444, -0.05280644, -0.19512466, -0.02906004, -0.21163146,\n",
       "          0.14182612,  0.21647853,  0.00089669, -0.28157642, -0.21670476,\n",
       "         -0.02999896,  0.04891038,  0.19234589,  0.17535841, -0.13379669,\n",
       "         -0.09867278,  0.17992401,  0.1983704 ,  0.20844513,  0.20111918,\n",
       "         -0.271074  ,  0.13002884,  0.26334494, -0.16348985, -0.08593477,\n",
       "         -0.03028041,  0.00656831,  0.13917837, -0.1300277 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 1.39581889e-01,  1.62687272e-01, -7.06195682e-02,\n",
       "         -5.04763424e-02,  2.09674358e-01,  2.52437204e-01,\n",
       "          1.62106544e-01, -4.97727394e-02, -1.64750949e-01,\n",
       "          1.17730170e-01],\n",
       "        [ 1.14451200e-01, -2.50773460e-01,  1.66766644e-02,\n",
       "         -3.86565775e-02, -1.93776250e-01, -2.28710189e-01,\n",
       "          1.88107520e-01, -1.42171934e-01,  1.67705715e-02,\n",
       "          5.09214997e-02],\n",
       "        [-1.93902448e-01,  1.14465714e-01, -1.55098349e-01,\n",
       "          3.00587714e-02, -2.69214183e-01,  2.42485195e-01,\n",
       "          2.60163158e-01, -1.34034947e-01, -9.41175371e-02,\n",
       "         -2.60594636e-01],\n",
       "        [ 2.50458091e-01, -4.68361229e-02, -2.16199800e-01,\n",
       "          5.99914789e-03, -1.02021590e-01,  4.38190699e-02,\n",
       "          4.50912118e-03, -2.50224501e-01, -1.20939821e-01,\n",
       "          8.32582712e-02],\n",
       "        [-1.53066829e-01, -1.53730378e-01, -1.35347113e-01,\n",
       "         -1.31201670e-01, -2.11887360e-01, -2.48840258e-01,\n",
       "          2.37897605e-01,  2.09617078e-01,  8.92538130e-02,\n",
       "          1.65654898e-01],\n",
       "        [ 1.83883935e-01,  7.83222914e-03, -2.58705616e-02,\n",
       "          9.55857635e-02, -1.09303847e-01,  1.30897105e-01,\n",
       "         -1.74546868e-01, -2.63700366e-01,  1.85098380e-01,\n",
       "         -1.30790189e-01],\n",
       "        [-1.57776177e-02, -2.34252930e-01,  1.37163818e-01,\n",
       "          2.56881088e-01, -1.77371740e-01, -9.85677987e-02,\n",
       "          2.44558960e-01,  2.60685295e-01,  6.95594251e-02,\n",
       "          2.67677516e-01],\n",
       "        [ 2.52110153e-01, -4.29646820e-02, -6.50937408e-02,\n",
       "         -1.07140213e-01, -2.82398492e-01, -2.64539450e-01,\n",
       "         -7.45603889e-02,  2.53497809e-01,  1.54074252e-01,\n",
       "          2.50174612e-01],\n",
       "        [-1.87083662e-01, -4.19100225e-02,  1.80654377e-01,\n",
       "          1.75421357e-01, -2.09701449e-01,  6.17194176e-03,\n",
       "         -8.56882334e-03, -1.63111433e-01,  2.23852307e-01,\n",
       "         -1.46091238e-01],\n",
       "        [ 2.76817352e-01,  5.37569523e-02,  2.68746525e-01,\n",
       "         -5.17216921e-02,  4.00341749e-02, -1.20572880e-01,\n",
       "          3.24553847e-02, -5.36060929e-02, -2.70120025e-01,\n",
       "          1.47809923e-01],\n",
       "        [ 1.03430092e-01, -1.38498381e-01,  1.73523098e-01,\n",
       "          1.18796706e-01,  1.78277642e-01,  2.42784470e-01,\n",
       "          2.30801702e-02,  1.30742729e-01,  2.72828192e-01,\n",
       "          6.09041750e-02],\n",
       "        [-2.45541662e-01, -4.80062664e-02, -1.38325885e-01,\n",
       "         -1.53436497e-01,  1.49563342e-01,  2.80638605e-01,\n",
       "          2.67851025e-01, -1.35422349e-02,  7.71018267e-02,\n",
       "          6.51380122e-02],\n",
       "        [-1.74939930e-02,  1.69814736e-01, -9.05411392e-02,\n",
       "         -5.48902750e-02, -5.22494018e-02, -1.59190029e-01,\n",
       "         -2.58120686e-01,  3.31478417e-02,  2.34186739e-01,\n",
       "         -2.21786469e-01],\n",
       "        [-4.17324901e-02,  1.37575150e-01, -2.77420461e-01,\n",
       "          1.42859519e-02,  6.27696514e-03, -1.49827436e-01,\n",
       "          1.50282443e-01,  2.66604692e-01,  8.92656446e-02,\n",
       "         -4.84855622e-02],\n",
       "        [ 2.79758185e-01,  4.32091653e-02, -1.07314691e-01,\n",
       "         -2.08400220e-01, -2.17680931e-02, -1.06487393e-01,\n",
       "          2.26470321e-01,  2.05659807e-01, -2.26640046e-01,\n",
       "          9.85310078e-02],\n",
       "        [-9.40406322e-03,  4.40598726e-02, -1.77996174e-01,\n",
       "         -2.80019253e-01,  1.36059523e-01,  2.59093016e-01,\n",
       "         -2.10309058e-01,  1.77171320e-01,  7.53256381e-02,\n",
       "          1.51849508e-01],\n",
       "        [ 1.04764909e-01, -7.89401233e-02,  1.34451300e-01,\n",
       "         -7.09244609e-03,  4.75676358e-02, -1.23178259e-01,\n",
       "         -2.84271419e-01, -1.39733627e-01,  4.91144955e-02,\n",
       "          2.28325337e-01],\n",
       "        [ 7.14643002e-02, -4.94652987e-03, -1.97657049e-01,\n",
       "         -7.66490698e-02,  1.52628124e-02, -1.44784912e-01,\n",
       "         -2.30369940e-01,  2.73322552e-01,  1.01636797e-01,\n",
       "          9.47495103e-02],\n",
       "        [ 1.35372490e-01, -2.20371038e-01,  6.49088621e-03,\n",
       "          1.84101313e-01,  2.60845393e-01, -3.45774591e-02,\n",
       "          7.47619569e-02,  7.49853849e-02, -2.65571982e-01,\n",
       "         -2.09687606e-01],\n",
       "        [ 1.07801467e-01,  2.74026304e-01, -4.33591157e-02,\n",
       "          8.34578574e-02, -2.44465753e-01,  6.88102543e-02,\n",
       "          2.17103690e-01,  1.38301313e-01,  2.48739123e-03,\n",
       "          1.04315817e-01],\n",
       "        [-2.52665192e-01, -4.01022732e-02,  1.41534507e-01,\n",
       "          2.79319376e-01,  1.38644964e-01, -1.91890761e-01,\n",
       "          2.15046644e-01, -1.38643056e-01,  1.82074279e-01,\n",
       "          5.27562499e-02],\n",
       "        [ 2.43040293e-01, -8.97027105e-02,  1.26301706e-01,\n",
       "         -2.41952151e-01, -6.37998432e-02,  7.53730834e-02,\n",
       "         -1.33700669e-02,  1.41570240e-01,  9.88705158e-02,\n",
       "         -1.28652707e-01],\n",
       "        [ 8.22261572e-02, -2.15444535e-01, -1.54414698e-01,\n",
       "          2.78215259e-01, -1.38524652e-01, -1.94709301e-02,\n",
       "          1.32550359e-01,  8.39393437e-02, -7.69923776e-02,\n",
       "          2.62772650e-01],\n",
       "        [-5.45731783e-02,  2.71833390e-01,  1.55223131e-01,\n",
       "          6.67648911e-02,  1.10516489e-01,  1.19511992e-01,\n",
       "          1.71363831e-01, -1.55443028e-01, -9.64251459e-02,\n",
       "          1.85809135e-01],\n",
       "        [ 2.27115005e-01, -9.81628448e-02,  1.82063282e-01,\n",
       "         -2.02152401e-01,  1.42067969e-02, -2.46536225e-01,\n",
       "         -2.27334768e-01, -1.86787277e-01, -2.71655321e-02,\n",
       "          2.27166384e-01],\n",
       "        [-1.53223991e-01, -2.19598860e-01,  4.46369946e-02,\n",
       "          9.71586406e-02, -1.74774021e-01, -3.62888128e-02,\n",
       "         -1.83694035e-01,  1.36962593e-01, -5.70861548e-02,\n",
       "         -9.72996354e-02],\n",
       "        [ 6.48715496e-02, -1.45136982e-01, -1.39706135e-02,\n",
       "          1.58738703e-01,  7.94872642e-03,  2.17111617e-01,\n",
       "          5.25375307e-02, -6.73128963e-02, -2.25821584e-01,\n",
       "          2.13297874e-01],\n",
       "        [-1.08610973e-01, -1.29734650e-01,  1.90202147e-01,\n",
       "         -2.62964964e-02, -1.48166671e-01, -3.79707664e-02,\n",
       "          2.82871932e-01, -5.07700443e-03, -2.30245978e-01,\n",
       "         -2.50259131e-01],\n",
       "        [-2.16879040e-01,  2.33841836e-02, -2.05210119e-01,\n",
       "          1.37562543e-01, -2.29275644e-01, -5.77348471e-03,\n",
       "          1.35893822e-01,  2.77021557e-01,  5.94074130e-02,\n",
       "         -4.59546596e-02],\n",
       "        [-1.85642242e-01,  2.35627294e-02, -2.04124436e-01,\n",
       "         -9.30165797e-02,  3.33147943e-02, -2.69399434e-01,\n",
       "          1.61073267e-01,  2.59862334e-01,  1.83187664e-01,\n",
       "          2.73517698e-01],\n",
       "        [ 5.24225831e-03,  2.72704571e-01, -2.56488979e-01,\n",
       "         -1.65282995e-01,  1.11251384e-01,  1.64675057e-01,\n",
       "         -1.10757083e-01, -1.35986358e-01,  4.29876447e-02,\n",
       "          1.03620499e-01],\n",
       "        [ 2.62329906e-01, -2.30881825e-01,  1.36207342e-01,\n",
       "         -1.55429512e-01,  1.64504051e-01, -1.46468431e-01,\n",
       "         -6.18639886e-02, -7.93896168e-02, -6.34268522e-02,\n",
       "          1.21790469e-01],\n",
       "        [-1.99365765e-01, -8.92558694e-03,  1.97905600e-02,\n",
       "         -1.74346328e-01, -2.30180621e-02,  1.99222565e-02,\n",
       "         -1.06728941e-01,  7.42878318e-02, -2.41157383e-01,\n",
       "         -1.76474169e-01],\n",
       "        [-2.81925052e-01, -7.88712800e-02,  1.18949652e-01,\n",
       "         -2.53818959e-01, -2.51354665e-01,  1.39471889e-02,\n",
       "          2.03496069e-01, -1.21462569e-01, -1.62827373e-01,\n",
       "          1.84164852e-01],\n",
       "        [-1.96935058e-01,  2.89042592e-02, -1.69764429e-01,\n",
       "         -6.52991682e-02, -5.11204749e-02, -3.30168903e-02,\n",
       "          2.28934318e-01,  2.62847275e-01, -2.59825587e-02,\n",
       "         -3.06041837e-02],\n",
       "        [ 9.64961052e-02, -2.23087072e-01, -4.80085760e-02,\n",
       "          1.41149104e-01,  2.16748148e-01, -2.24259734e-01,\n",
       "         -4.11480665e-04, -1.45502493e-01, -1.82506740e-02,\n",
       "          2.71026403e-01],\n",
       "        [-2.21254274e-01,  1.36918187e-01,  1.05767846e-01,\n",
       "          3.86338234e-02,  2.65994579e-01, -1.20683551e-01,\n",
       "          1.41527534e-01,  2.20639378e-01, -9.06571597e-02,\n",
       "          1.64990723e-01],\n",
       "        [-1.44303441e-01,  1.75874859e-01, -9.25368071e-02,\n",
       "         -2.32770443e-01,  1.45362616e-02,  2.40723789e-02,\n",
       "         -1.45230055e-01, -2.49120027e-01,  1.43202007e-01,\n",
       "          1.46092057e-01],\n",
       "        [-2.20687270e-01,  2.58322924e-01, -1.32057741e-01,\n",
       "          1.49872899e-03,  2.48214602e-02, -2.82185197e-01,\n",
       "         -7.85374641e-02,  3.76739502e-02, -1.96728677e-01,\n",
       "         -7.46620148e-02],\n",
       "        [-7.93406665e-02,  2.73780674e-01, -1.30954757e-01,\n",
       "          9.49004889e-02,  1.99993998e-01,  2.49184072e-02,\n",
       "          2.51187533e-01,  5.42429686e-02,  7.05782175e-02,\n",
       "          5.71351051e-02],\n",
       "        [ 2.66815513e-01, -1.51135117e-01,  1.63406283e-01,\n",
       "         -7.76428282e-02,  1.55822933e-01, -5.99882752e-02,\n",
       "          7.13225603e-02,  2.32253343e-01,  3.32710147e-02,\n",
       "          2.01912224e-02],\n",
       "        [-2.33425289e-01,  6.49875700e-02,  1.51357740e-01,\n",
       "          1.42804682e-02,  2.36480027e-01, -2.61814594e-01,\n",
       "         -2.63355970e-02, -2.58897811e-01, -6.57569468e-02,\n",
       "          2.41797894e-01],\n",
       "        [ 1.99024826e-01, -2.02812210e-01,  1.80660427e-01,\n",
       "          5.20268083e-03, -2.18893707e-01,  4.49522734e-02,\n",
       "          2.32684940e-01, -7.91159570e-02,  2.24783093e-01,\n",
       "         -2.14581996e-01],\n",
       "        [ 8.46135616e-03, -4.39562649e-02,  9.30634141e-02,\n",
       "         -2.73218542e-01, -2.49330074e-01, -1.32972956e-01,\n",
       "         -8.99536908e-02,  1.52714759e-01,  2.77826875e-01,\n",
       "          6.50146306e-02],\n",
       "        [-1.08502150e-01,  5.86466491e-02,  1.65608943e-01,\n",
       "          1.30005747e-01, -1.37916580e-01, -4.59947735e-02,\n",
       "         -2.52825409e-01,  2.06133127e-01, -2.71156073e-01,\n",
       "          1.05095059e-01],\n",
       "        [-5.66277653e-02,  1.36670768e-02, -1.88586935e-01,\n",
       "          1.48247987e-01,  6.48441911e-03, -2.64919698e-01,\n",
       "         -2.18989164e-01, -1.97820395e-01, -2.04358310e-01,\n",
       "          2.20075846e-02],\n",
       "        [ 1.93754524e-01, -1.74820423e-04, -2.61471748e-01,\n",
       "         -1.69496939e-01, -2.70609558e-01, -1.67184174e-02,\n",
       "         -5.92023283e-02,  2.17768282e-01, -1.28978774e-01,\n",
       "         -1.70193285e-01],\n",
       "        [-1.79905891e-01,  2.32139319e-01,  2.05062121e-01,\n",
       "         -1.45784780e-01,  9.67682600e-02,  1.02056831e-01,\n",
       "          2.68485039e-01,  1.05643064e-01, -7.93958604e-02,\n",
       "          2.03198165e-01],\n",
       "        [ 1.26067162e-01, -1.31735414e-01, -9.07285064e-02,\n",
       "          2.17370778e-01,  3.97168100e-02, -2.72852331e-01,\n",
       "          7.96347558e-02, -1.49865463e-01, -1.95971847e-01,\n",
       "          1.15486771e-01],\n",
       "        [ 2.45422810e-01, -6.51401281e-03,  1.17628664e-01,\n",
       "         -1.74613193e-01,  9.94497538e-02,  1.06797367e-01,\n",
       "          1.70315355e-01,  2.22264439e-01,  2.21755475e-01,\n",
       "          2.66001076e-01],\n",
       "        [ 1.04392260e-01, -1.67599916e-01, -6.37316704e-03,\n",
       "          2.74686784e-01, -1.23911947e-01,  2.08652765e-01,\n",
       "         -1.85450613e-02, -5.93654662e-02,  2.57772356e-01,\n",
       "         -9.67391431e-02],\n",
       "        [ 2.72025257e-01, -1.97628617e-01,  2.02825665e-03,\n",
       "          2.15949744e-01,  2.46987194e-01, -9.03627872e-02,\n",
       "         -1.02156758e-01,  1.88633174e-01,  3.06257904e-02,\n",
       "          2.23016828e-01],\n",
       "        [ 2.59930760e-01,  2.47600704e-01, -7.65648782e-02,\n",
       "          1.41021073e-01, -1.84774697e-01, -1.42486453e-01,\n",
       "          2.60179788e-01,  4.35351431e-02,  2.52421886e-01,\n",
       "          6.99977577e-02],\n",
       "        [-1.68240666e-02,  2.26285428e-01, -8.25997442e-02,\n",
       "          1.81199104e-01, -1.02698848e-01, -4.32968140e-03,\n",
       "          1.35462105e-01, -1.43442065e-01,  2.92370915e-02,\n",
       "          2.39196450e-01],\n",
       "        [-7.94693083e-02,  1.35157555e-01,  2.15884447e-02,\n",
       "         -9.34907198e-02,  1.35265708e-01,  2.79145092e-01,\n",
       "         -2.42738038e-01, -1.33881867e-01,  1.88127249e-01,\n",
       "          6.67860806e-02],\n",
       "        [ 7.69549012e-02, -1.98074222e-01,  2.48549879e-02,\n",
       "         -1.89934269e-01, -2.46267736e-01, -9.54320729e-02,\n",
       "          1.70566946e-01,  1.93009973e-02, -1.30027935e-01,\n",
       "          2.46997803e-01],\n",
       "        [ 4.20067012e-02, -4.95783687e-02, -1.07062966e-01,\n",
       "         -9.33681726e-02, -8.91965330e-02, -2.51917243e-01,\n",
       "         -2.40865320e-01,  1.50910079e-01, -2.06785411e-01,\n",
       "         -7.21868575e-02],\n",
       "        [ 1.06054276e-01, -1.63857996e-01, -2.56927133e-01,\n",
       "          1.38050795e-01,  2.84384340e-01,  1.54249042e-01,\n",
       "          1.11703306e-01,  2.07169950e-01,  2.56805420e-02,\n",
       "          2.43927270e-01],\n",
       "        [-5.88121712e-02, -2.29398936e-01, -8.36091191e-02,\n",
       "         -2.62699723e-01, -7.08110780e-02,  4.36862111e-02,\n",
       "          1.02894306e-01,  5.85055053e-02, -1.40049577e-01,\n",
       "         -3.43441963e-02],\n",
       "        [-1.20253950e-01, -2.53238231e-01, -2.23055243e-01,\n",
       "          1.10750020e-01, -7.32807517e-02,  8.43643844e-02,\n",
       "          2.04145908e-04, -2.77614623e-01,  1.82186276e-01,\n",
       "         -4.95261550e-02],\n",
       "        [-5.03720641e-02,  2.00428843e-01,  1.83259279e-01,\n",
       "          2.66205639e-01,  2.19599217e-01,  4.33095694e-02,\n",
       "         -1.31209001e-01,  1.12275481e-01, -1.05201602e-02,\n",
       "         -5.65871745e-02],\n",
       "        [ 1.15508348e-01, -4.72573042e-02, -1.50010273e-01,\n",
       "          8.58855247e-02,  1.53990060e-01, -7.97623843e-02,\n",
       "         -1.81507200e-01,  8.01919401e-02, -1.41108245e-01,\n",
       "         -1.74176991e-02],\n",
       "        [-2.42503628e-01, -1.37982160e-01, -1.17499828e-02,\n",
       "         -4.46979553e-02, -2.27050170e-01, -2.84349561e-01,\n",
       "          1.19815528e-01,  2.61043519e-01,  1.81708634e-02,\n",
       "         -2.49683365e-01],\n",
       "        [-5.81248552e-02,  3.85330319e-02,  2.44829744e-01,\n",
       "          2.29938358e-01, -1.45879418e-01, -2.24605680e-01,\n",
       "         -2.52781093e-01, -2.43384078e-01,  1.29093111e-01,\n",
       "          2.31277972e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10cada20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be able to view summary whenever you want, say after adding each layer, add input shape at beginning only\n",
    "model = keras.Sequential(name='keras1')\n",
    "model.add(layers.Input(shape=(3, ))) #shape is shape of each sample, not batch\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67256a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name = 'model2')\n",
    "model.add(layers.Input(shape=(3, )))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e7cdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "=================================================================\n",
      "Total params: 8,576\n",
      "Trainable params: 8,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b660fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,866\n",
      "Trainable params: 9,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedbc1a",
   "metadata": {},
   "source": [
    "# FUNCTIONAL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5891dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3, ), name='my_inputs')\n",
    "features = layers.Dense(64, activation='relu')(inputs)\n",
    "outputs = layers.Dense(10, activation='softmax')(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe31cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model with multiple inputs and outputs:\n",
    "#Customer support ranking by priority\n",
    "#3 inputs, 2 outputs\n",
    "#inputs = title(text), text_body(text), tags(categorical)\n",
    "#outputs = ranking(sigmoid), dept(softmax)\n",
    "\n",
    "vocab_size=10000\n",
    "num_tags = 100\n",
    "depts = 4\n",
    "\n",
    "#inputs\n",
    "title = keras.Input(shape=(vocab_size, ), name='title')\n",
    "text_body = keras.Input(shape=(vocab_size, ), name='textbody')\n",
    "tags = keras.Input(shape=(num_tags,), name='tags')\n",
    "\n",
    "#features\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation='relu')(features)\n",
    "\n",
    "#outputs\n",
    "priority = layers.Dense(1, activation='sigmoid', name='priority')(features)\n",
    "dept = layers.Dense(depts, activation='softmax', name='dept')(features)\n",
    "\n",
    "#model\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, dept])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "463d03d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 12ms/step - loss: 29.7634 - priority_loss: 0.3174 - dept_loss: 29.4460 - priority_mean_absolute_error: 0.4839 - dept_accuracy: 0.2344\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 23.3584 - priority_loss: 0.3161 - dept_loss: 23.0422 - priority_mean_absolute_error: 0.4814 - dept_accuracy: 0.2445\n"
     ]
    }
   ],
   "source": [
    "#providing dummy input and target data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocab_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocab_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "dept_data = np.random.randint(0, 2, size=(num_samples, depts))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss=['mean_squared_error', 'categorical_crossentropy'],\n",
    "             metrics=[['mean_absolute_error'],['accuracy']])\n",
    "\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "         [priority_data, dept_data],\n",
    "         epochs=1)\n",
    "\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "              [priority_data, dept_data])\n",
    "\n",
    "priority_preds, dept_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c234d9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d3ed60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x16e07ad47f0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x16e07ad4a30>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x16e07ad44f0>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x16e07ad4d60>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x16e07ad4ee0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x16e07ad65e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x16e07aefee0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a716663c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'title:0' shape=(None, 10000) dtype=float32>,\n",
       " <tf.Tensor 'textbody:0' shape=(None, 10000) dtype=float32>,\n",
       " <tf.Tensor 'tags:0' shape=(None, 100) dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d1160ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input of layer  0  =  Tensor(\"title:0\", shape=(None, 10000), dtype=float32)\n",
      "Output of layer  0  =  Tensor(\"title:0\", shape=(None, 10000), dtype=float32) \n",
      "\n",
      "Input of layer  1  =  Tensor(\"textbody:0\", shape=(None, 10000), dtype=float32)\n",
      "Output of layer  1  =  Tensor(\"textbody:0\", shape=(None, 10000), dtype=float32) \n",
      "\n",
      "Input of layer  2  =  Tensor(\"tags:0\", shape=(None, 100), dtype=float32)\n",
      "Output of layer  2  =  Tensor(\"tags:0\", shape=(None, 100), dtype=float32) \n",
      "\n",
      "Input of layer  3  =  [<tf.Tensor 'title:0' shape=(None, 10000) dtype=float32>, <tf.Tensor 'textbody:0' shape=(None, 10000) dtype=float32>, <tf.Tensor 'tags:0' shape=(None, 100) dtype=float32>]\n",
      "Output of layer  3  =  Tensor(\"concatenate/concat:0\", shape=(None, 20100), dtype=float32) \n",
      "\n",
      "Input of layer  4  =  Tensor(\"concatenate/concat:0\", shape=(None, 20100), dtype=float32)\n",
      "Output of layer  4  =  Tensor(\"dense_7/Relu:0\", shape=(None, 64), dtype=float32) \n",
      "\n",
      "Input of layer  5  =  Tensor(\"dense_7/Relu:0\", shape=(None, 64), dtype=float32)\n",
      "Output of layer  5  =  Tensor(\"priority/Sigmoid:0\", shape=(None, 1), dtype=float32) \n",
      "\n",
      "Input of layer  6  =  Tensor(\"dense_7/Relu:0\", shape=(None, 64), dtype=float32)\n",
      "Output of layer  6  =  Tensor(\"dept/Softmax:0\", shape=(None, 4), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    print(\"Input of layer \", i, \" = \", model.layers[i].input)\n",
    "    print(\"Output of layer \", i, \" = \", model.layers[i].output, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8759e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add new output using existing features: difficulty : ['easy', 'medium', 'hard']\n",
    "#instead of retraining whole model, we can use features from layer 4\n",
    "\n",
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation='softmax', name='difficulty')(features)\n",
    "\n",
    "new_model = keras.Model(inputs=[title, text_body, tags],\n",
    "                        outputs=[priority, dept, difficulty])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2877adc",
   "metadata": {},
   "source": [
    "# MODEL SUBCLASSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c28e74",
   "metadata": {},
   "source": [
    "Basically implementing layers and shit from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd2b87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(keras.Model):\n",
    "    \n",
    "    def __init__ (self, depts):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation='relu')\n",
    "        self.priority_scorer = layers.Dense(1, activation='sigmoid')\n",
    "        self.dept_clf = layers.Dense(depts, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        title = inputs['title']\n",
    "        text_body = inputs['text_body']\n",
    "        tags = inputs['tags']\n",
    "        \n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        dept = self.dept_clf(features)\n",
    "        \n",
    "        return priority, dept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "180c4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(depts=4)\n",
    "\n",
    "priority, dept = model({'title': title_data, 'text_body': text_body_data, 'tags': tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b87e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Model.call of <__main__.Model object at 0x0000016E024EE3A0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Model.call of <__main__.Model object at 0x0000016E024EE3A0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 31.1029 - output_1_loss: 0.3236 - output_2_loss: 30.7793 - output_1_mean_absolute_error: 0.4898 - output_2_accuracy: 0.2352\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 20.2386 - output_1_loss: 0.3534 - output_2_loss: 19.8852 - output_1_mean_absolute_error: 0.5186 - output_2_accuracy: 0.2453\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss=['mean_squared_error', 'categorical_crossentropy'],\n",
    "             metrics=[['mean_absolute_error'],['accuracy']])\n",
    "\n",
    "model.fit({'title': title_data, 'text_body': text_body_data, 'tags': tags_data},\n",
    "         [priority_data, dept_data],\n",
    "         epochs=1)\n",
    "\n",
    "model.evaluate({'title': title_data, 'text_body': text_body_data, 'tags': tags_data},\n",
    "              [priority_data, dept_data])\n",
    "\n",
    "priority_preds, dept_preds = model.predict({'title': title_data, 'text_body': text_body_data, 'tags': tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351e4f1",
   "metadata": {},
   "source": [
    "# CUSTOM METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50aedeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing custom RMSE metric\n",
    "\n",
    "class RMSE(keras.metrics.Metric):\n",
    "    \n",
    "    def __init__(self, name='rmse', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name='mse_sum', initializer='zeros')\n",
    "        self.total_samples = self.add_weight(name='total_samples', dtype='int32', initializer='zeros')\n",
    "        \n",
    "    def update_state(self, ytrue, ypred, sample_weight=None):\n",
    "        ytrue = tf.one_hot(ytrue, depth=tf.shape(ypred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(ytrue-ypred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(ypred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "        \n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum/tf.cast(self.total_samples, tf.float32))\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce512e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method RMSE.update_state of <__main__.RMSE object at 0x0000016E086B5AC0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method RMSE.update_state of <__main__.RMSE object at 0x0000016E086B5AC0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2931 - accuracy: 0.9128 - rmse: 7.1851 - val_loss: 0.1554 - val_accuracy: 0.9564 - val_rmse: 7.3592\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1631 - accuracy: 0.9544 - rmse: 7.3569 - val_loss: 0.1257 - val_accuracy: 0.9670 - val_rmse: 7.3998\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1372 - accuracy: 0.9629 - rmse: 7.3869 - val_loss: 0.1195 - val_accuracy: 0.9690 - val_rmse: 7.4231\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9702 - rmse: 7.4371\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model(): \n",
    " inputs = keras.Input(shape=(28 * 28,))\n",
    " features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    " features = layers.Dropout(0.5)(features)\n",
    " outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    " model = keras.Model(inputs, outputs)\n",
    " return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data() \n",
    "\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\", RMSE()]) \n",
    "\n",
    "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels)) \n",
    "\n",
    "test_metrics = model.evaluate(test_images, test_labels) \n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece186a5",
   "metadata": {},
   "source": [
    "# CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b44ae256",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2),\n",
    "    keras.callbacks.ModelCheckpoint(filepath='checkpoint_path.keras', monitor='val_loss', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c7e2867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2928 - accuracy: 0.9138 - val_loss: 0.1522 - val_accuracy: 0.9572\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1636 - accuracy: 0.9538 - val_loss: 0.1180 - val_accuracy: 0.9678\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1379 - accuracy: 0.9634 - val_loss: 0.1246 - val_accuracy: 0.9672\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1235 - accuracy: 0.9683 - val_loss: 0.1153 - val_accuracy: 0.9736\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1161 - accuracy: 0.9711 - val_loss: 0.1085 - val_accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1103 - accuracy: 0.9727 - val_loss: 0.1139 - val_accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1047 - accuracy: 0.9752 - val_loss: 0.1096 - val_accuracy: 0.9769\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1027 - accuracy: 0.9762 - val_loss: 0.1188 - val_accuracy: 0.9766\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0954 - accuracy: 0.9773 - val_loss: 0.1199 - val_accuracy: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e088b4a60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
    "model.fit(train_images, train_labels, epochs=10, callbacks=callbacks, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddb9fb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\godbo\\anaconda3\\envs\\deepl\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\godbo\\anaconda3\\envs\\deepl\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./')\n",
    "model1 = keras.models.load_model('checkpoint_path.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73b29265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985086e",
   "metadata": {},
   "source": [
    "# CUSTOM CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91cd1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fde78ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "        label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d2a1f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2955 - accuracy: 0.9120 - val_loss: 0.1491 - val_accuracy: 0.9569\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1631 - accuracy: 0.9540 - val_loss: 0.1152 - val_accuracy: 0.9670\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1386 - accuracy: 0.9633 - val_loss: 0.1174 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1257 - accuracy: 0.9681 - val_loss: 0.1163 - val_accuracy: 0.9712\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1171 - accuracy: 0.9702 - val_loss: 0.1085 - val_accuracy: 0.9751\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1087 - accuracy: 0.9737 - val_loss: 0.1086 - val_accuracy: 0.9765\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1061 - accuracy: 0.9750 - val_loss: 0.1179 - val_accuracy: 0.9752\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1016 - accuracy: 0.9762 - val_loss: 0.1197 - val_accuracy: 0.9751\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0963 - accuracy: 0.9775 - val_loss: 0.1303 - val_accuracy: 0.9749\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0973 - accuracy: 0.9780 - val_loss: 0.1111 - val_accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e145b1c70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels,\n",
    "         epochs=10,\n",
    "         callbacks=[LossHistory()],\n",
    "         validation_data = (val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49081b23",
   "metadata": {},
   "source": [
    "# TENSORBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecd651f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   2/1563 [..............................] - ETA: 6:19 - loss: 2.3514 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.4829s). Check your callbacks.\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2908 - accuracy: 0.9130 - val_loss: 0.1342 - val_accuracy: 0.9593\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1492 - accuracy: 0.9540 - val_loss: 0.0970 - val_accuracy: 0.9711\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1113 - accuracy: 0.9652 - val_loss: 0.0999 - val_accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0950 - accuracy: 0.9703 - val_loss: 0.0805 - val_accuracy: 0.9765\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0854 - accuracy: 0.9733 - val_loss: 0.0760 - val_accuracy: 0.9777\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0760 - accuracy: 0.9753 - val_loss: 0.0744 - val_accuracy: 0.9786\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0703 - accuracy: 0.9777 - val_loss: 0.0755 - val_accuracy: 0.9788\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0622 - accuracy: 0.9795 - val_loss: 0.0861 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0610 - accuracy: 0.9795 - val_loss: 0.0734 - val_accuracy: 0.9805\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0539 - accuracy: 0.9824 - val_loss: 0.0755 - val_accuracy: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e15a31970>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./')\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "         epochs=10,\n",
    "         callbacks=[tensorboard],\n",
    "         validation_data = (val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01fb78e",
   "metadata": {},
   "source": [
    "# CUSTOM TRAINING AND EVALUATION LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c40edc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "#Train function for each loop\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape: \n",
    "        predictions = model(inputs, training=True) \n",
    "        loss = loss_fn(targets, predictions) \n",
    "    gradients = tape.gradient(loss, model.trainable_weights) \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights)) \n",
    "    logs = {} \n",
    "    for metric in metrics: \n",
    "        metric.update_state(targets, predictions) \n",
    "        logs[metric.name] = metric.result() \n",
    "    loss_tracking_metric.update_state(loss) \n",
    "    logs[\"loss\"] = loss_tracking_metric.result() \n",
    "    return logs \n",
    "\n",
    "\n",
    "\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93664848",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparseCategoricalAccuracy' object has no attribute 'reset_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mreset_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m training_dataset:\n\u001b[0;32m      8\u001b[0m         logs \u001b[38;5;241m=\u001b[39m train_step(inputs_batch, targets_batch)\n",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36mreset_metrics\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_metrics\u001b[39m():\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m---> 26\u001b[0m         \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_state\u001b[49m()\n\u001b[0;32m     27\u001b[0m     loss_tracking_metric\u001b[38;5;241m.\u001b[39mreset_state()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparseCategoricalAccuracy' object has no attribute 'reset_state'"
     ]
    }
   ],
   "source": [
    "#The loop itself\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94e4f7fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparseCategoricalAccuracy' object has no attribute 'reset_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((val_images, val_labels))\n\u001b[0;32m     16\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mreset_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m val_dataset:\n\u001b[0;32m     19\u001b[0m     logs \u001b[38;5;241m=\u001b[39m test_step(inputs_batch, targets_batch) \n",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36mreset_metrics\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_metrics\u001b[39m():\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m---> 26\u001b[0m         \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_state\u001b[49m()\n\u001b[0;32m     27\u001b[0m     loss_tracking_metric\u001b[38;5;241m.\u001b[39mreset_state()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparseCategoricalAccuracy' object has no attribute 'reset_state'"
     ]
    }
   ],
   "source": [
    "#Evaluation loop\n",
    "\n",
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False) \n",
    "    loss = loss_fn(targets, predictions)\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "        loss_tracking_metric.update_state(loss)\n",
    "        logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "    \n",
    "    \n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics() \n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch) \n",
    "print(\"Evaluation results:\") \n",
    "for key, value in logs.items(): \n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657089d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
